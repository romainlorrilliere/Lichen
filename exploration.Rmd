---
title: '**Exploration des données LichenGo**'
author: "Laure & Romain"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    fig_height: 12
    fig_width: 16
    toc: yes
    toc_depth: 2
    number_sections: true
    code_folding: hide
  pdf_document:
    toc: yes
    toc_depth: '1'
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE)
```

## Initialisation

Installation des packages
```{r install packages}

library(data.table)
library(dplyr)
library(ggplot2)

source("fun_exploration.r")

```


# Les données 

## Les données lichens

L'ensemble des données sont stockée dans un dossier nommée _data/_

### Données de Grégory Agnello dans la vallée du Rhône

* _Data_Lyon.csv_ : nom des sites + abondance des lichens par face et par quadra
* _Data_rhone_coord.csv_ : nom des sites + abondance des lichens par face et par quadrat + nom de commune + coordonnés (en L93) => __c'est ce fichier qu'on utilise__

Ce jeux de données à déjà fait l'objet d'un traitement elle sont
relativement propre. 
Mais, les données ont été collectées entre avril 2009 et avril 2012 et
il n'y a pas d'info sur l'espèce de l'arbre ou sa circonférence.

On renomme aussi les colonnes pour supprimer les majuscules et faire plus propre

Ajout de plusieurs colonnes
* _site\_id_: id du site avec un _R_ comme prefixe
* _date_str_: date dans un format character -> "avril 2009 - avril 2012"
* _annee_str_: année(s) dans un format character -> "2009-2012"
* _annee_min_: première année du suivie -> 2009
* _annee_max_: dernière année du suivie -> 2012
* _arbre\_sp\_fr_: nom français de l'espèce de l'arbre -> _NA_
* _arbre\_sp\_sc_: nom scientifique de l'espèce de l'arbre -> _NA_
* _arbre\_circ_: circonference l'arbre -> _NA_
* _region_: Rhone
* _arbre\_id_: id de l'arbre la concaténation du site_id et de l'_arbre\_num_ 
* _arbre\_nbtot_: le nombre total d'arbre du site 




```{r data_rhone}
## importation

lesColonnes <- c("date_str","annee_str","annee_min","annee_max","region","site_id","site_code","commune","insee","dept","lon_l93","lat_l93","arbre_id","arbre_num","arbre_nbtot","arbre_sp_fr","arbre_sp_sc","arbre_circ","face","sample","sp","ab")

d.rhone <- fread("data/data_rhone_coord.csv")

d.rhone$date_str <- "avril 2009 - avril 2012"
d.rhone$annee_str <- "2009-2012"
d.rhone$annee_min <- "2009"
d.rhone$annee_max <- "2012" 
d.rhone$arbre_sp_fr <- NA
d.rhone$arbre_sp_sc <- NA
d.rhone$arbre_circ <- NA
d.rhone$region <- "Rhone"
colnames(d.rhone)[colnames(d.rhone)=="NAME"] <- "commune"
colnames(d.rhone)[colnames(d.rhone)=="site"] <- "site_code"
d.rhone$site_id <- paste("R",d.rhone$site_code,sep="_")
colnames(d.rhone)[colnames(d.rhone)=="CODE_INSEE"] <- "insee"
colnames(d.rhone)[colnames(d.rhone)=="Dept"] <- "dept"
colnames(d.rhone)[colnames(d.rhone)=="X"] <- "lon_l93"
colnames(d.rhone)[colnames(d.rhone)=="Y"] <- "lat_l93"
colnames(d.rhone)[colnames(d.rhone)=="arbre"] <- "arbre_num"
d.rhone$arbre_id <- paste(d.rhone$site_id,d.rhone$arbre_num,sep="_")
d.rhone$sample <- as.numeric(gsub("R","",d.rhone$sample))

d.max <- aggregate(arbre_num ~ site_id,d.rhone,max)
colnames(d.max)[2] <- "arbre_nbtot"
cat("Distribution du nombre d'arbre par site\n")
summary(as.factor(d.max$arbre_nbtot))

d.rhone <- data.table(inner_join(d.rhone,d.max))

d.rhone <- d.rhone[,lesColonnes,with=FALSE]

head(d.rhone)
cat("Les dimension de la table rhone\n")
dim(d.rhone)

```

### Données de Jonathan Signoret dans le Grand-Est


* _data_grandest.csv_ : id site + coord (en L93) + taxon arbre (pas toujours renseigné) + circonférence de l'arbre (pas toujours renseignée) + abondance des lichens par face et par quadrat => __c'est ce fichier qu'on utilise__

Ces données de la région Grand Est sont à formater, les 4 faces et 5 réplicat sont en colonnes.


 * On renomme les colonnes pour supprimer les majuscules et être cohérents avec les données du rhône.
 * On transforme les données d'abondance d'espèce pour être cohérent avec les données du Rhône.
 * On ajoute les colonnes commune, insee, departement pour être cohérent avec les données du Rhône.

__Attention__ dans les données brutes, il n'y a pas d'identifiant de l'arbre. On peut en créer un en croisant les données d'espèce de l'arbre et de circonférence. Si ces infos sont manquantes, on n'utilise pas ces données.

On a 54 sites avec 1 arbre, 61 avec 2 et 52 avec 3 -> on ne peut pas "dégrader" les données en passant de 5 arbres à  3 avec ce jeu de données.

On ajoute dans les deux jeux de donnéées le nombre d'arbres total par site.


Ajout de plusieurs colonnes
* _site\_id_: id du site avec un _GE_ comme prefixe
* _date_str_: date dans un format character -> "dans les annees 2000s"
* _annee_str_: année(s) dans un format character -> "2000~2009"
* _annee_min_: première année du suivie -> 2000
* _annee_max_: dernière année du suivie -> 2009
* _region_: Grand-Est
* _arbre\_num_: increment de l'arbre sur le site -> ici construit par l'algorithme
* _arbre\_id_: id de l'arbre la concaténation du site_id et de l'_arbre\_num_ 
* _arbre\_nbtot_: le nombre total d'arbre du site 
* _commune_: commune -> NA
* _insee_: code insee de la commune ->  NA
* _dept_: departement -> NA



il faut nettoyer les noms des lichen 

Pour connaitre pouvoir retrouver l'arbre sur lequel ont été réalisé
les samples on ne garde pas les site pour lesquelles ont a pas
d'espèces d'arbre et pas de circonférence.


```{r data_grandest}

d.ge <- fread("data/data_grandest.csv")


premiere_col <- c("site_code","lon_l93","lat_l93","arbre_sp_fr","arbre_sp_sc","arbre_circ","sp")
colnames(d.ge)[1:length(premiere_col)] <- premiere_col

d.ge$region <- "Grand-Est"
d.ge$site_id <- paste("GE",d.ge$site_code,sep="_")
d.ge$arbre <- paste0(d.ge$arbre_sp_sc,d.ge$arbre_circ)
d.unique <- data.table(unique(d.ge[,c("site_id","arbre")]))
d.unique <- d.unique[,arbre_num := 1:.N,by=site_id]

##head(d.unique)

d.max <- aggregate(arbre_num ~ site_id, d.unique,max)
###head(d.max)
colnames(d.max)[2] <- "arbre_nbtot"

cat("Distribution du nombre d'arbre par site\n")
summary(as.factor(d.max$arbre_nbtot))

d.unique <- inner_join(d.unique,d.max)
##head(d.unique)

d.ge <- inner_join(d.ge,d.unique)
##head(d.ge)

premiere_col <- c(premiere_col,"arbre","arbre_num","arbre_nbtot","region","site_id")
d.ge <- data.table(melt(d.ge, id.vars = premiere_col))
##head(d.ge)
d.ge$face <- substr(d.ge$variable,1,1)
vecFace <- c("N"="Nord","E"="Est","S"="Sud","O"="Ouest")
d.ge$face<- vecFace[d.ge$face]
d.ge$sample <- as.numeric(substr(d.ge$variable,2,nchar(as.character(d.ge$variable))))

colnames(d.ge)[colnames(d.ge)=="value"] <- "ab"

d.ge$date_str <- "dans les annees 2000s"
d.ge$annee_str <- "2000~2009"
d.ge$annee_min <- "2000"
d.ge$annee_max <- "2009" 
d.ge$commune <- NA
d.ge$insee <- NA
d.ge$dept <- NA
head(d.ge)

d.ge$arbre_id <- paste(d.ge$site_id,d.ge$arbre_num,sep="_")

d.ge <- d.ge[,lesColonnes,with=FALSE]



head(d.ge)

cat("Dimension de la table Grand-Est:\n")
dim(d.ge)
```


### Assemblage

__L'assemblage__

On fusionne les deux jeux de données et on exporte : _data\_lichens\_rhone\_grandest.csv_



```{r data}
d <- rbind(d.rhone,d.ge)

cat("Dimension de la table finale:\n")
dim(d)
write.csv(d,"data/data_lichen_rhone_grandest.csv",row.names=FALSE)

```

__Reste à faire!__

- il faut nettoyer les noms des lichen 



## Les données qualité de l'air

### Rhones



* Fichier _extraction\_donnees\_sorbonne.xlsx_ : données horaires de mesure du 01/01/2004 au 01/01/2008
Un feuillet par polluant (ozone, dioxyde d'azote, PM10 et PM2,5)
* Fichier _donnees\_sorbonne.csv_ : données journaliéres de mesure du
01/01/2008 au 01/01/2013. Ici tous les polluants sont dans le méme feuillet (monoxyde d'azote, dioxyde d'azote, PM10 + nombreuses spécifications (ajustées, résultantes...)
Fichier coordonnees_stations : coordonnees des stations de mesure en L93

Nous réorganisons les jeux de données pour avoir les colonnes
suivantes: 
organisme, station, date,heure,mesure,type,valeur,etat...


Les polluants sont traduit en code, renseigné dans le fichier : _library/code_polluants.csv_


__Les donnes de 2004 à 2008: _extraction\_donnees\_sorbonne.xlsx_ -->
A faire! __


__Les donnes de 2008 à 2013: _donnees\_sorbonne.csv_ __

```{r air_rhone}

air.rhone2 <- fread("data/donnees_sorbonne.csv")

dim(air.rhone2)
head(air.rhone2)


air.rhone2bis <- air.rhone2[5:nrow(air.rhone2),]
col <- apply(air.rhone2[1:4,],2,paste,collapse="|")
colnames(air.rhone2bis) <- col
colnames(air.rhone2bis)[1] <- "date_complet"
#head(air.rhone2bis)

air.rhone2bis <- data.table(melt(air.rhone2bis, id.vars = "date_complet"))
head(air.rhone2bis)


col <- apply(air.rhone2[1:4,],2,paste,collapse="#")


air.rhone2 <- air.rhone2[5:nrow(air.rhone2),]

colnames(air.rhone2) <- col
colnames(air.rhone2)[1] <- "date_complet"

air.rhone2 <- data.table(melt(air.rhone2, id.vars = "date_complet"))
head(air.rhone2)


varunique <- unique(air.rhone2[,"variable"])
dim(varunique)

varunique$variable <- as.character(varunique$variable)
variable <- varunique$variable

temp <- strsplit(variable,"#") 

mat  <- matrix(unlist(temp), ncol=4, byrow=TRUE)
dunique   <- cbind(variable,as.data.frame(mat))
colnames(dunique) <- c("variable","station","polluant","periode","type")

air.rhone2 <- inner_join(air.rhone2,dunique)

air.rhone2 <- data.table(air.rhone2[,-2])
air.rhone2 <- dcast(air.rhone2, formula = date_complet + station + polluant + periode ~ type, value.var = "value")
air.rhone2$Valeur <- as.numeric(as.character(air.rhone2$Valeur))
air.rhone2$Etat <- as.factor(air.rhone2$Etat)

code_po <- fread("library/code_polluants.csv")
head(code_po)

air.rhone2 <- left_join(air.rhone2,code_po)
air.rhone2$code_polluant <- as.factor(air.rhone2$code_polluant)

head(air.rhone2)
summary(air.rhone2)

air.rhone2$date <- as.Date(substr(air.rhone2$date_complet,1,10),"%d/%m/%Y")
head(air.rhone2)
summary(air.rhone2)
```


Les données de 2004 à 2007 sont horaires. On les moyenne
quotidiennement. 

```{r rhone2_2_day, eval=TRUE}
air.rhone2.jour <- aggregate(Valeur ~ date + station + code_polluant, air.rhone2, mean, na.rm = TRUE)
colnames(air.rhone2.jour)[ncol(air.rhone2.jour)] <- "valeur"


tab_etat <- aggregate(Valeur ~ date + station + code_polluant + Etat,air.rhone2,length)
tab_etat <- dcast(tab_etat,formula = date + station + code_polluant ~ Etat, value.var="Valeur")
tab_etat[is.na(tab_etat)] <- 0
tab_etat$tot <- tab_etat$A + tab_etat$D + tab_etat$N + tab_etat$R

tab_etat$A <- round(tab_etat$A / tab_etat$tot,3)
tab_etat$D <- round(tab_etat$D / tab_etat$tot,3)
tab_etat$N <- round(tab_etat$N / tab_etat$tot,3)
tab_etat$R <- round(tab_etat$R / tab_etat$tot,3)

colnames(tab_etat)[4:8] <- c("etat_A","etat_D","etat_N","etat_R","nb_mesure")

air.rhone2.jour <- inner_join(air.rhone2.jour,tab_etat)

head(air.rhone2.jour)

cat("Sauvegarde de la table: data/polluant_rhone2_jour.csv \n")
write.csv(air.rhone2.jour,"data/polluant_rhone2_jour.csv",row.names=FALSE)
```


__Reste à faire!__

- Il faut récupérer le sens des états 

